\chapter{Methodology}

The proposed methodology outlines a secure and efficient federated learning system that utilizes dual Zero-Knowledge Proofs (ZKPs) to ensure end-to-end verifiability. The methodology follows an iterative, round-based training structure, integrating cryptographic proof systems and adaptive rigor tuning.

\section{Overview}
Each training round consists of:
\begin{enumerate}
    \item \textbf{Client-side training and proof generation} using zk-SNARKs (PySNARK).
    \item \textbf{Server-side verification, aggregation, and proof generation} using Groth16 zk-SNARKs.
\end{enumerate}

\section{Step-by-Step Procedure}

\subsection*{Step 1: Initialization}
\begin{itemize}
    \item The server initializes the global model \( w^{(0)} \), server momentum \( m^{(0)} = 0 \), and proof rigor parameters.
    \item The server distributes the initial model to all participating clients.
    \item Clients load their local data and prepare for training.
\end{itemize}

\subsection*{Step 2: Client-Side Operations}
For each round \( t \), each client \( i \) performs the following:
\begin{enumerate}
    \item Downloads global model \( w^{(t)} \).
    \item Computes model update \( \Delta_i^{(t)} \) by applying SGD for \( E \) local epochs:
    \[
    w_i^{(t+1)} = w^{(t)} - \eta \sum_{e=1}^E \nabla L_i(w_i^{(e)}; \mathcal{B}_e), \quad \Delta_i^{(t)} = w_i^{(t+1)} - w^{(t)}.
    \]
    where \( \mathcal{B}_e \) represents mini-batches from client \( i \)'s local dataset.
    \item Applies \textbf{FixedPointQuantizer} to convert \( \Delta_i^{(t)} \) to 8-bit fixed point representation:
    \[
    \hat{\Delta}_i^{(t)} = \text{Quantize}(\Delta_i^{(t)}, \text{bits}=8, \text{scale}=2^7)
    \]
    \item Computes parameter norms and validation metrics for proof circuit inputs.
    \item Generates a zk-SNARK proof \( \pi_i^{\text{client}} \) for the statement:
    \begin{itemize}
        \item The model update \( \Delta_i^{(t)} \) was generated from SGD using valid, committed local data.
        \item The data used meets certain size and format requirements.
    \end{itemize}
    \item Sends \( (\Delta_i^{(t)}, \pi_i^{\text{client}}) \) to the server.
\end{enumerate}

\subsection*{Step 3: Server-Side Operations}
Upon receiving submissions from all clients, the \textbf{SecureFlowerServer} performs:
\begin{enumerate}
    \item \textbf{Client Proof Verification}: Verifies each \( \pi_i^{\text{client}} \) using batch zk-SNARK verification through \texttt{ClientProofManager.verify\_proof()}.
    \item \textbf{Update Filtering}: Filters out invalid updates and applies weight decay if configured:
    \[
    \tilde{\Delta}_i^{(t)} = \Delta_i^{(t)} - \lambda w^{(t)}
    \]
    where \( \lambda \) is the weight decay coefficient.
    \item \textbf{FedJSCM Aggregation}: Implemented by \texttt{FedJSCMAggregator} class:
    \begin{enumerate}
        \item Computes weighted average of client updates:
        \[
        \bar{\Delta}^{(t)} = \sum_{i \in V} p_i \tilde{\Delta}_i^{(t)}
        \]
        where \( p_i = \frac{n_i}{\sum_{j \in V} n_j} \) and \( n_i \) is client \( i \)'s data size.
        \item Updates server momentum with adaptive coefficient:
        \[
        m^{(t+1)} = \gamma_{\text{eff}}^{(t)} m^{(t)} + \bar{\Delta}^{(t)}
        \]
        where \( \gamma_{\text{eff}}^{(t)} = \gamma \cdot \text{momentum\_decay}^t \) for adaptive momentum.
        \item Applies momentum to global model:
        \[
        w^{(t+1)} = w^{(t)} + \eta_{\text{global}} \cdot m^{(t+1)}
        \]
    \end{enumerate}
    \item \textbf{Server Proof Generation}: Uses \texttt{ServerProofManager} to generate Groth16 zk-SNARK proof \( \pi^{\text{server}} \) proving:
    \begin{itemize}
        \item Correct weighted averaging: \( \sum_{i \in V} p_i = 1 \) and weights match data sizes
        \item Valid momentum update: \( m^{(t+1)} = \gamma m^{(t)} + \bar{\Delta}^{(t)} \)
        \item Correct model update: \( w^{(t+1)} = w^{(t)} + \eta_{\text{global}} m^{(t+1)} \)
        \item Parameter bounds: \( \|\Delta_i^{(t)}\|_2 \leq \text{max\_update\_norm} \)
        \item Public inputs include \( \text{hash}(w^{(t)}) \), \( \text{hash}(w^{(t+1)}) \), and round number \( t \)
    \end{itemize}
    \item \textbf{State Management}: Updates training metrics via \texttt{StabilityMonitor} for dynamic proof rigor adjustment.
    \item \textbf{Broadcast}: Distributes \( (w^{(t+1)}, \pi^{\text{server}}, \text{proof\_rigor}^{(t+1)}) \) to clients.
\end{enumerate}

\subsection*{Dynamic Rigor}
The system adjusts proof complexity based on training stability:
\begin{itemize}
    \item \textbf{Planned High Rigor}: Full verification for unstable training (future implementation)
    \item \textbf{Planned Medium Rigor}: Partial verification for moderate stability (future implementation)
    \item \textbf{Planned Low Rigor}: Basic verification for stable convergence (future implementation)
    \item \textbf{Current Implementation}: Fixed rigor level with 8.7s proof generation time
\end{itemize}

\section{System Components and Tools}

\section{Implementation}
\begin{itemize}
    \item \textbf{Framework}: Flower with custom secure clients and servers
    \item \textbf{Client Proofs}: PySNARK-based zk-SNARK circuits for SGD verification
    \item \textbf{Server Proofs}: Groth16 zk-SNARKs for aggregation verification
    \item \textbf{Quantization}: Fixed-point quantization for circuit compatibility
\end{itemize}

This methodology ensures verifiability, robustness, and efficiency across the entire FL pipeline, making it suitable for high-stakes and privacy-critical applications.

\section{Experimental Design}

Our experimental validation follows a multi-phase approach with statistical rigor, incorporating baseline testing, secure FL evaluation, and comprehensive analysis across diverse datasets and model architectures.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{experimental_framework.png}
    \caption{Experimental Framework Design}
    \label{fig:experimental_framework}
\end{figure}

\section{Infrastructure}

\subsection{Hardware Requirements}

Infrastructure requirements differ significantly between server and client components due to computational asymmetry:

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Component} & \textbf{Server} & \textbf{Client} \\
\midrule
\textbf{CPU} & 8+ vCPUs & 4+ vCPUs \\
\textbf{Memory} & 32+ GB RAM & 8+ GB RAM \\
\textbf{Storage} & 500+ GB SSD & 100+ GB SSD \\
\textbf{Network} & 10+ Gbps & 1+ Gbps \\
\midrule
\textbf{AWS Instance} & m5.2xlarge+ & t3.large+ \\
\textbf{Cost (USD/hr)} & \$0.384+ & \$0.083+ \\
\bottomrule
\end{tabular}
\caption{Infrastructure Requirements}
\label{tab:infrastructure_specs}
\end{table}

\textbf{Key Requirements:}
\begin{itemize}
    \item \textbf{Server}: Fast proof verification with batch processing capabilities
    \item \textbf{Client}: High CPU/memory for intensive proof generation workload
    \item \textbf{Network}: Secure channels with proof transmission optimization
\end{itemize}

\subsection{Software Stack}

\begin{itemize}
    \item \textbf{Framework}: Flower v1.5+ (federated learning), PyTorch v2.0+ (ML training)
    \item \textbf{Cryptography}: PySNARK (client proofs), Groth16 (server proofs)
    \item \textbf{Infrastructure}: Ubuntu 22.04, Docker, Docker Compose
    \item \textbf{Communication}: gRPC over TLS, HTTP/2 for proof transmission
\end{itemize}

\subsection{Deployment Architecture}

\textbf{Development Setup:}
\begin{itemize}
    \item Docker Compose orchestration with service scaling
    \item Shared compute resources with process isolation
    \item Simulated non-IID data distribution across clients
\end{itemize}

\textbf{Production Considerations:}
\begin{itemize}
    \item High availability server configuration with failover
    \item Load balancing based on proof verification capacity
    \item TLS 1.3 security with comprehensive audit logging
    \item Monitoring stack for performance and security metrics
\end{itemize}

\subsection{Scaling Behavior}

\begin{table}[H]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Scaling Factor} & \textbf{Scaling Behavior} \\
\midrule
Client Count & Linear scaling \\
Model Size & Super-linear scaling \\
Training Data & Linear scaling \\
\bottomrule
\end{tabular}
\caption{System Scaling Characteristics}
\label{tab:scaling_behavior}
\end{table}

\section{Datasets}
\begin{itemize}
    \item \textbf{MNIST}: Handwritten digits, 60K samples, non-IID distribution
    \item \textbf{Fashion-MNIST}: Clothing images, 60K samples, balanced classes
    \item \textbf{CIFAR-10}: Natural images, 50K samples, challenging classification
    \item \textbf{Medical}: Healthcare datasets with privacy requirements
    \item \textbf{Financial}: Transaction data with regulatory compliance needs
    \item \textbf{Synthetic}: Controlled datasets for scalability testing
\end{itemize}
Each client typically holds 5-20\% of the dataset with configurable non-IID distributions to simulate realistic federated learning scenarios.

\section{Proof Configuration and Circuit Design}

\subsection{Client-Side Proof Circuits}
\begin{itemize}
    \item \textbf{SGD Verification}: Complete training step verification using PySNARK
    \item \textbf{Data Commitment}: Cryptographic commitments to local training data
    \item \textbf{Parameter Bounds}: Verification of update magnitude constraints
    \item \textbf{Quantization}: 8-bit fixed-point representation with scale factor $2^7$
    \item \textbf{Circuit Size}: $\mathcal{O}(n \cdot d)$ constraints for $n$ batch size, $d$ parameters
\end{itemize}

\subsection{Server-Side Proof Circuits}
\begin{itemize}
    \item \textbf{Aggregation Verification}: Groth16 proofs for weighted averaging correctness
    \item \textbf{Momentum Updates}: FedJSCM algorithm verification with adaptive coefficients
    \item \textbf{Weight Validation}: Proof of correct client weight computation
    \item \textbf{State Consistency}: Model state transitions and integrity verification
\end{itemize}

This comprehensive infrastructure setup enables reproducible, secure, and scalable simulation of federated learning with privacy-preserving, verifiable computation while providing realistic performance characteristics for deployment planning.
