\documentclass[a4paper,12pt]{report}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{array}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{longtable}
\usepackage{pgfgantt}
\usepackage[backend=biber,style=authoryear]{biblatex}
\addbibresource{ref.bib}

\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  numbers=left,
  numbersep=5pt
}

\begin{document}

%---------------- Title Page ----------------%
\begin{titlepage}
    \centering
    \vspace*{0.6cm}
    \includegraphics[scale=0.28]{logotu.jpg}\par
    \vspace{1cm}
    {\Huge \textbf{Tribhuvan University}}\\[0.4cm]
    {\Large Institute of Engineering}\\[0.2cm]
    {\Large Pulchowk Campus}\\
    \vspace{1.5cm}
    {\LARGE A Project Report On}\\[0.6cm]
    {\Huge \textbf{Secure Federated Learning with Zero-Knowledge Proofs}}\\[0.7cm]
    {\Large \textbf{Client-side PySNARK Proofs \& Server-side Groth16 Aggregation}}\\
    \vspace{1.8cm}
    {\large \textbf{Submitted By:}}\\[0.3cm]
    {\large Bindu Paudel (PUL078BCT032)}\\
    {\large Krishant Timilsina (PUL078BCT045)}\\[1cm]
    {\large \textbf{Submitted To:}}\\[0.3cm]
    {\large Department of Electronics \& Computer Engineering}\\
    \vspace{1.5cm}
    {\large July, 2025}
\end{titlepage}

\pagenumbering{roman}

%---------------- Acknowledgement ----------------%
\chapter*{Acknowledgements}
\addcontentsline{toc}{chapter}{Acknowledgements}
We express our sincere gratitude to our supervisor, Associate Professor Arun Kumar Timalsina,
Ph.D., Department of Electronics and Computer Engineering, Pulchowk Campus, for his
constant support and guidance. We also thank our faculty, friends, and family members who
supported us throughout this project.

\tableofcontents
\listoffigures
\listoftables

\clearpage
\pagenumbering{arabic}

%---------------- Abstract ----------------%
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

Federated Learning (FL) enables model training across distributed devices without sharing private data. However, two trust problems remain unresolved: (1) clients may lie about their local training, and (2) servers may aggregate updates incorrectly. To address this, we built a dual-verification pipeline combining client-side PySNARK proofs with server-side zk-SNARK (Groth16) proofs implemented through Circom and \texttt{snarkjs}. Clients prove correctness of their model updates (delta bounds, hashes, update integrity), while the server generates a proof that the global aggregation step (FedJSCM momentum update) was performed faithfully.

This report presents the implemented system, detailed methodology, improved circuits, test results, and remaining work toward a production-ready verifiable FL framework.

\textbf{Keywords:} Federated Learning, Zero-Knowledge Proofs, PySNARK, Groth16, Circom, Momentum Aggregation, Verifiable ML.

%---------------- Introduction ----------------%
\chapter{Introduction}

\section{Background}
Federated Learning decentralizes machine learning by allowing clients to train models locally. While privacy is preserved, FL lacks cryptographic guarantees of correctness. Malicious clients may submit fabricated gradients, and servers may intentionally or accidentally alter updates. Therefore, an FL system must not rely solely on trust.

This project introduces cryptographic verifiability into FL using zero-knowledge techniques:
\begin{enumerate}
    \item Client-side verification: PySNARK-based proofs embedded into client training.
    \item Server-side verification: Circom-based Groth16 proof of correct aggregation.
\end{enumerate}

\section{Motivation}
Most FL systems validate correctness heuristically—by anomaly detection or simple thresholding. These approaches fail against strong adversaries. Our motivation is to achieve mathematically verifiable correctness of FL updates without exposing client data.

\section{Project Contributions}
This report documents:
\begin{itemize}
    \item A complete dual-verification pipeline.
    \item Reliable JSON proof structure from clients.
    \item A fully implemented FedJSCM aggregation layer with momentum.
    \item A Circom Groth16 circuit encoding the aggregation logic.
    \item Integration tests, observations, and error diagnosis.
\end{itemize}

%---------------- Problem Statement ----------------%
\chapter{Problem Statement and Objectives}

\section{Problem Statement}
The integrity of updates in FL is not guaranteed. We target two verification gaps:
\begin{enumerate}
    \item Clients must prove that their parameter updates were produced by legitimate local training.
    \item Servers must prove that they executed the aggregation step correctly.
\end{enumerate}

\section{Objectives}
\begin{itemize}
  \item Implement client-side proofs using PySNARK inside *ClientProofManager*.
  \item Implement server-side Groth16 aggregation proof using Circom inside *ServerProofManager*.
  \item Integrate both verification steps in *SecureFlowerStrategy*.
  \item Provide reliable tests for proof generation and verification.
\end{itemize}

%---------------- Literature Review ----------------%
\chapter{Literature Review}

\section{Related Work}

\subsection{Federated Learning Foundations}
Federated Learning (FL) was popularized by Google~\parencite{mcmahan2017fedavg} as a decentralized method for collaboratively training machine learning models without sharing raw data. The foundational FedAvg algorithm formalized the process of sending global parameters to clients, performing several epochs of local SGD, and aggregating weighted updates on the server.

Subsequent research has expanded FL to address challenges such as:
\begin{itemize}
    \item Communication efficiency via compression, quantization, and partial participation.
    \item Personalization methods to improve performance under non-IID client distributions.
    \item Optimization improvements to stabilize convergence in heterogeneous data settings.
\end{itemize}

However, one limitation persists across nearly all FL variants: the server and clients are assumed to behave honestly. In real deployments, this assumption is fragile.

\subsection{Security and Robustness in FL}
Significant literature explores robustness against adversarial or faulty participants. Byzantine-resilient aggregation techniques such as Krum~\parencite{blanchard2017krum}, Trimmed Mean, and Multi-Krum filter anomalous updates using geometric/statistical heuristics. While useful in practice, these mechanisms:
\begin{itemize}
    \item provide no \emph{cryptographic guarantees},
    \item can fail under coordinated attacks,
    \item treat the server itself as trusted,
    \item and do not verify that local training was performed correctly.
\end{itemize}

Thus, robustness alone is insufficient for fully verifiable FL.

\subsection{Cryptographic Approaches to Verifiable FL}

Privacy-focused techniques such as Differential Privacy~\parencite{dwork2006dp} and Secure Aggregation~\parencite{bonawitz2017secureagg} improve confidentiality but do not verify correctness of computation. They ensure that updates remain private, not that they were computed honestly.

Verifiable computation using Zero-Knowledge Proofs (ZKPs) addresses this gap. Prototype systems such as ZKFL~\parencite{roth2022zkfl} introduced zk-SNARK-based proofs ensuring that clients correctly execute gradient descent steps. However, such systems exhibit limitations:
\begin{enumerate}
    \item High computational cost for proof generation.
    \item Proofs cover \emph{only} the client-side computation.
    \item No verification of server-side aggregation.
    \item Limited scalability to real-world models or training dynamics.
\end{enumerate}

Thus, literature still lacks a fully verifiable end-to-end FL pipeline.

\subsection{Our Contribution}
Compared to prior work, our system implements:

\begin{itemize}
    \item \textbf{Client-side PySNARK proofs}: Clients attach lightweight arithmetic-circuit proofs validating their parameter update bounds and consistency.
    
    \item \textbf{Server-side zk-SNARKs}: The server generates Groth16 proofs (via Circom + SnarkJS) demonstrating correct execution of the FedJSCM momentum aggregation rule.

    \item \textbf{Dual verification pipeline}: Both parties prove correctness — addressing gaps in existing literature that only validate one side.

    \item \textbf{Adaptive proof rigor}: The server dynamically tunes verification strictness based on stability signals (gradient norms, loss fluctuations).

    \item \textbf{Practical implementation}: Full integration with the Flower FL framework, real PyTorch training, and reproducible testbench.
\end{itemize}

This constitutes one of the first practical demonstrations of both client and server verifiability in a federated learning workflow.

\section{Related Theory}

\subsection{Federated Learning (FL)}
FL aims to minimize a global loss across $N$ clients:

\[
L(w) = \sum_{i=1}^{N} p_i L_i(w),
\]

where each client $i$ has data proportion $p_i$ and local loss function $L_i(w)$.

Each client performs local SGD:

\[
w_i^{(t+1)} = w^{(t)} - \eta \nabla L_i(w^{(t)}),
\]

and returns the update:

\[
\Delta_i = w_i^{(t+1)} - w^{(t)}.
\]

Our verification system checks that these deltas are well-formed and bounded.

\subsection{Stochastic Gradient Descent (SGD)}
SGD updates parameters according to:

\[
w \leftarrow w - \eta \nabla L(w; x, y),
\]

computed over mini-batches of private data.  
The client PySNARK proof ensures consistency between the claimed update and expected structural properties of SGD (e.g., norms, hashing, structural integrity).

\subsection{Zero-Knowledge Proofs (ZKPs)}

A ZKP allows a prover to demonstrate correct computation without revealing private inputs.

A valid ZKP must satisfy:
\begin{itemize}
    \item \textbf{Completeness} — honest proofs always verify.
    \item \textbf{Soundness} — cheating provers cannot fake correctness.
    \item \textbf{Zero-knowledge} — no private information leaks.
\end{itemize}

\subsection{zk-SNARKs (Groth16)}

zk-SNARKs provide succinct and fast-verifying proofs. The server uses Groth16 to prove that it applied the FedJSCM aggregation correctly:

\[
m^{(t+1)} = \gamma m^{(t)} + \sum_i p_i \Delta_i,
\quad
w^{(t+1)} = w^{(t)} + m^{(t+1)}.
\]

This prevents server-side tampering.

\subsection{FedJSCM Aggregation}
FedJSCM is a momentum-based variant particularly effective for non-IID client distributions:

\[
m^{(t+1)} = \gamma m^{(t)} + \sum_{i=1}^{N} p_i \Delta_i,
\]

\[
w^{(t+1)} = w^{(t)} + m^{(t+1)}.
\]

Our Circom circuit implements this rule to guarantee server honesty.

\subsection{Dynamic Proof Granularity}
To optimize overhead:
\begin{itemize}
    \item During unstable training: strict verification.
    \item During stable phases: reduced proof frequency or lighter proofs.
\end{itemize}

This balances security and runtime efficiency.


\chapter{Proposed Experimental Setup}

This chapter describes the experimental setup used to evaluate our dual-verifiable federated learning framework. Unlike prior theoretical work relying on STARKs or blockchain integration, our implementation focuses on a practical and reproducible environment using PySNARK for client proofs and Groth16 SNARKs for server aggregation proofs.

\section{Infrastructure Overview}

\subsection{Local and Cloud-Based Simulation}

The system is deployed using a hybrid setup:
\begin{itemize}
    \item A central \textbf{server node} running the Flower FL server, aggregation logic, and Groth16 proof generation.
    \item Multiple \textbf{client nodes} running PyTorch training and producing PySNARK proofs.
\end{itemize}

These nodes may run:
\begin{itemize}
    \item on a single machine using multiple processes,
    \item across local VMs, or
    \item optionally on cloud machines for large-scale tests.
\end{itemize}

\subsection*{VM Configuration (Representative Setup)}

\begin{table}[H]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Role} & \textbf{vCPUs} & \textbf{RAM} & \textbf{Purpose} \\
\midrule
Server Node & 4 & 8--16 GB & Groth16 proving, aggregation \\
Client Nodes (5--10) & 2 & 4 GB & Local training + PySNARK proofs \\
\bottomrule
\end{tabular}
\caption{Representative VM configuration for FL simulation}
\end{table}

No blockchain or Cairo/STARK tooling is used — the system relies entirely on PySNARK and Circom.

\section{Software Stack}

\subsection{Client Nodes}
\begin{itemize}
    \item Ubuntu 22.04
    \item PyTorch for model training
    \item Flower client implementation
    \item PySNARK for local proof generation
\end{itemize}

Each client executes *ClientProofManager* and contributes FL updates with accompanying proofs.

\subsection{Server Node}
\begin{itemize}
    \item Flower server with custom \textit{SecureFlowerStrategy}
    \item FedJSCM aggregator
    \item Circom 2.0 + SnarkJS for Groth16 proof generation
    \item Python interface for witness creation and proof verification
\end{itemize}

\section{Datasets}

Because the primary goal is validating the verification pipeline rather than model accuracy, lightweight datasets are used:
\begin{itemize}
    \item Synthetic low-dimensional datasets for debugging the circuit.
    \item Small image or tabular datasets for realistic FL training.
\end{itemize}

The datasets are partitioned into non-IID splits to reflect real FL behavior.

\section{Proof Configuration}

\subsection{Client-Side Proofs (PySNARK)}
Clients generate:
\begin{itemize}
    \item Norm bound proofs
    \item Hash consistency proofs (initial weights, updated weights, deltas)
\end{itemize}

These proofs are embedded as JSON metadata.

\subsection{Server-Side Proofs (Groth16)}
The server generates:
\begin{itemize}
    \item A zk-SNARK ensuring correct FedJSCM aggregation
    \item Inputs include deltas, weights, old momentum, and coefficients
\end{itemize}

\section{Reproducibility}
The entire pipeline can be reproduced on:
\begin{itemize}
    \item a single machine (debug mode),
    \item multi-VM setup,
    \item cloud simulation for scaling experiments.
\end{itemize}







%---------------- Methodology ----------------%
\chapter{Methodology: Step-by-Step System Flow}

The entire project follows a pipeline-driven methodology aligned with real FL operation.

\section{1. Client Local Training}
Each client receives:
\begin{itemize}
  \item Global model \( w^{(t)} \)
  \item Local epochs and batch size
  \item Proof settings (proof rigor, PySNARK enabling)
\end{itemize}

Clients compute:
\[
\Delta_i = w_i^{(t+1)} - w^{(t)}
\]

\section{2. Client Proof Generation}
Implemented inside *\textit{ClientProofManager.generate\_training\_proof()}*.
It performs:
\begin{enumerate}
  \item Hashing: initial weights, updated weights, delta.
  \item Computing norms and verifying they fall within expected ranges.
  \item Running PySNARK:
  \begin{itemize}
      \item If PySNARK runtime exists, *\textit{\_generate\_pysnark\_delta\_bound\_proof()}* produces a proof that \(\|\Delta\|\) is bounded.
      \item Otherwise, metadata with `"enabled": false` is inserted.
  \end{itemize}
  \item JSON packaging of proof object.
\end{enumerate}

\section{3. Transmission of Proof to Server}
Clients attach the JSON proof inside Flower's FitRes metrics under key \texttt{zkp\_proof}.

\section{4. Server Verification of Client Proof}
Performed inside *\textit{ServerProofManager.verify\_client\_proof()}*:
\begin{itemize}
  \item Recomputes expected delta from the submitted model.
  \item Recomputes required hashes.
  \item Compares against JSON proof.
  \item Verifies PySNARK metadata if present.
\end{itemize}

Only verified client updates are aggregated.

\section{5. FedJSCM Aggregation}
Aggregation uses:
\[
m^{(t+1)} = \gamma m^{(t)} + \sum_i p_i \Delta_i,
\quad
w^{(t+1)} = w^{(t)} + m^{(t+1)}.
\]

Implemented in *\textit{FedJSCMAggregator.aggregate()}*.

\section{6. Server-Side zk-SNARK Generation}
The server constructs a proof that:
\begin{itemize}
  \item It applied weights correctly.
  \item It computed momentum correctly.
  \item It produced correct new parameters.
\end{itemize}

Pipeline:
\begin{enumerate}
  \item *\textit{ServerProofManager.\_create\_aggregation\_circuit()}*  
        Generates the Circom circuit.
  \item *\textit{ServerProofManager.\_prepare\_snark\_inputs()}*  
        Converts tensors to witness JSON.
  \item *\textit{ServerProofManager.\_generate\_snark\_proof()}*  
        Calls Circom + snarkjs to output a Groth16 proof.
\end{enumerate}

\section{7. Adaptive Proof Rigor}
*SecureFlowerStrategy* dynamically adjusts client and server verification strictness based on stability feedback:
\begin{itemize}
  \item More unstable training \(\Rightarrow\) higher rigor.
  \item Stable training \(\Rightarrow\) lighter proofs.
\end{itemize}

%---------------- Testing and Results ----------------%
\chapter{Testing and Current Results}

\section{Client PySNARK Proof Tests}
Tests verify:
\begin{itemize}
    \item JSON proof schema correctness.
    \item Hash correctness.
    \item Norm recomputation matches.
\end{itemize}

Output example:
\begin{verbatim}
PySNARK ENABLED ✓
TEST PASSED ✓
\end{verbatim}

\section{Server Verification Tests}
Test confirms server correctly verifies PySNARK-backed proofs:
\begin{verbatim}
Server verification of client PySNARK-backed proof: OK
\end{verbatim}

\section{Server SNARK Aggregation Test}
Current failure: Circom parse error due to version mismatch and line-ending corruption.

This is not a logic error; it is an environment formatting issue.  
We provide a reproducible checklist in the next chapter.



\chapter{Project Status: Achievements and Remaining Work}

\section{Achievements To Date}

\subsection{Client-Side}
\begin{itemize}
    \item Fully implemented \textit{ClientProofManager} with PySNARK support.
    \item Automatic proof attachment to Flower \textit{FitRes} messages.
    \item Stable JSON proof schema including hashing, norms, and PySNARK metadata.
    \item Comprehensive unit tests confirming:
    \begin{itemize}
        \item correct delta reconstruction,
        \item correct hash consistency,
        \item correct norm computations,
        \item correct behavior when PySNARK is disabled.
    \end{itemize}
\end{itemize}

\subsection{Server-Side}
\begin{itemize}
    \item Implemented full FedJSCM aggregation logic.
    \item Completed Circom circuit generation pipeline for Groth16.
    \item Added witness generation, SNARK proof generation, and verification functions.
    \item Server now rejects malformed or unverifiable client proofs.
\end{itemize}

\subsection{Integration}
\begin{itemize}
    \item Custom \textit{SecureFlowerStrategy} coordinating:
    \begin{itemize}
        \item client proof verification,
        \item adaptive proof rigor,
        \item server SNARK verification.
    \end{itemize}
    \item End-to-end FL training runs with proof exchange.
\end{itemize}

\section{Remaining Work}

\subsection{Critical Tasks}
\begin{itemize}
    \item Finalize Circom circuit compatibility (eliminate parse errors).
    \item Ensure deterministic witness generation for reproducible SNARK proofs.
    \item Optimize aggregation circuit for larger models (quantization / batching).
\end{itemize}

\subsection{Enhancements}
\begin{itemize}
    \item Expand client proofs with stronger PySNARK constraints.
    \item Add proof caching and periodic server proofs for efficiency.
    \item Explore integration with on-chain verifiers for decentralization.
\end{itemize}

\subsection{Evaluation}
\begin{itemize}
    \item Measure runtime overhead on varying number of clients.
    \item Benchmark PySNARK vs Groth16 cost.
    \item Stress test under adversarial mismatched deltas.
\end{itemize}







%---------------- Conclusion ----------------%
\chapter{Conclusion}

We implemented a dual-verification federated learning system combining client-side PySNARK proofs with server-side zk-SNARK aggregation proofs. The client verification pipeline is functional and robust. The server SNARK pipeline is implemented, but final testing depends on local Circom/snarkjs compatibility. This progress report outlines the full methodology, technical achievements, testing results, and clear steps forward.

\printbibliography

\end{document}
